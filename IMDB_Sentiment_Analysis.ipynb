{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcsuWgrVb8urRar2MsB+Ru"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# ---\n","# My Submission for the IMDb Sentiment Analysis Task\n","# ---\n","\n","# === 1. SETUP: IMPORTING THE NECESSARY LIBRARIES ===\n","# I'll need pandas for data handling, scikit-learn for the ML parts, and nltk for text processing.\n","import pandas as pd\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Download the specific NLTK packages we need for text cleaning\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# === 2. DATA LOADING AND INITIAL INSPECTION ===\n","print(\"Starting the process...\")\n","# Using the robust 'python' engine and skipping bad lines to handle file errors.\n","try:\n","    reviews_df = pd.read_csv('IMDB Dataset.csv', engine='python', on_bad_lines='skip')\n","    print(\"Dataset loaded successfully.\")\n","    print(f\"The dataset has {reviews_df.shape[0]} rows and {reviews_df.shape[1]} columns.\")\n","except FileNotFoundError:\n","    print(\"Error: 'IMDB Dataset.csv' not found. Please make sure it's uploaded to Colab.\")\n","\n","# Let's look at the first few rows to see what we're dealing with.\n","print(\"\\n--- First 5 rows of the raw data ---\")\n","print(reviews_df.head())\n","\n","# === 3. TEXT PREPROCESSING AND CLEANING ===\n","# This is a crucial step to prepare the text for the model.\n","# I'll convert to lowercase, remove HTML/punctuation, and then use lemmatization to get the root of words.\n","\n","lemmatizer = WordNetLemmatizer()\n","english_stop_words = set(stopwords.words('english'))\n","\n","def clean_review_text(text):\n","    # Check if the text is a valid string, otherwise return empty\n","    if not isinstance(text, str):\n","        return \"\"\n","\n","    # Simple cleaning: lowercase and remove HTML tags/punctuation\n","    text = text.lower()\n","    text = re.sub(r'<.*?>', '', text)\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","\n","    # Tokenization: split the review into a list of words\n","    words = text.split()\n","\n","    # Advanced cleaning: remove stopwords and lemmatize\n","    # This helps the model focus on the words that carry the most meaning.\n","    cleaned_words = [lemmatizer.lemmatize(word) for word in words if word not in english_stop_words]\n","\n","    return \" \".join(cleaned_words)\n","\n","print(\"\\nCleaning and preprocessing all the movie reviews...\")\n","reviews_df['review'] = reviews_df['review'].apply(clean_review_text)\n","print(\"Preprocessing complete.\")\n","\n","# Let's check the data again after cleaning\n","print(\"\\n--- First 5 rows after cleaning ---\")\n","print(reviews_df.head())\n","\n","\n","# === 4. PREPARING DATA FOR THE MODEL ===\n","# The model needs numerical data, so I'll convert sentiments to 1s and 0s.\n","reviews_df['sentiment'] = reviews_df['sentiment'].map({'positive': 1, 'negative': 0})\n","\n","# Separate the features (the reviews) from the labels (the sentiment)\n","features = reviews_df['review']\n","labels = reviews_df['sentiment']\n","\n","# Split the data into a training set (80%) and a testing set (20%)\n","X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n","\n","print(f\"\\nData has been split into {len(X_train)} training samples and {len(X_test)} testing samples.\")\n","\n","# === 5. FEATURE EXTRACTION (TF-IDF VECTORIZATION) ===\n","# Now, I'll convert the cleaned text into numerical vectors using TF-IDF.\n","# This method is smart because it gives higher weight to more important words.\n","# I'm also using n-grams (1, 2) to capture pairs of words like \"not good\".\n","print(\"\\nConverting text data to numerical vectors with TF-IDF...\")\n","tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)\n","\n","# Learn the vocabulary from the training data and transform it\n","X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n","\n","# Use the same vocabulary to transform the test data\n","X_test_tfidf = tfidf_vectorizer.transform(X_test)\n","print(\"Vectorization complete.\")\n","print(f\"The vocabulary size is {len(tfidf_vectorizer.get_feature_names_out())} features.\")\n","\n","\n","# === 6. MODEL TRAINING AND EVALUATION ===\n","# Time to train the models and see how they perform!\n","\n","# --- Model A: Logistic Regression ---\n","print(\"\\n--- Training the Logistic Regression Classifier ---\")\n","logistic_classifier = LogisticRegression(solver='liblinear', C=1.0)\n","logistic_classifier.fit(X_train_tfidf, y_train)\n","predictions_lr = logistic_classifier.predict(X_test_tfidf)\n","\n","# Evaluate the model\n","accuracy_lr = accuracy_score(y_test, predictions_lr)\n","print(f\"Logistic Regression Final Accuracy: {accuracy_lr:.4f}\")\n","print(\"Classification Report:\")\n","print(classification_report(y_test, predictions_lr))\n","\n","# --- Model B: Linear Support Vector Classifier (SVC) ---\n","print(\"\\n--- Training the Linear SVC Classifier ---\")\n","svm_classifier = LinearSVC(C=0.5, random_state=42)\n","svm_classifier.fit(X_train_tfidf, y_train)\n","predictions_svc = svm_classifier.predict(X_test_tfidf)\n","\n","# Evaluate the model\n","accuracy_svc = accuracy_score(y_test, predictions_svc)\n","print(f\"Linear SVC Final Accuracy: {accuracy_svc:.4f}\")\n","print(\"Classification Report:\")\n","print(classification_report(y_test, predictions_svc))\n","\n","print(\"\\nProcess finished!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8IakmSJ-pNwm","executionInfo":{"status":"ok","timestamp":1758732831503,"user_tz":-330,"elapsed":5093,"user":{"displayName":"Srisaihariharan S","userId":"11385530915815435812"}},"outputId":"aa4da03d-ccd6-43ed-f361-a2cf10a64c56"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Starting the process...\n","Dataset loaded successfully.\n","The dataset has 3137 rows and 2 columns.\n","\n","--- First 5 rows of the raw data ---\n","                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n","\n","Cleaning and preprocessing all the movie reviews...\n","Preprocessing complete.\n","\n","--- First 5 rows after cleaning ---\n","                                              review sentiment\n","0  one reviewer mentioned watching oz episode you...  positive\n","1  wonderful little production filming technique ...  positive\n","2  thought wonderful way spend time hot summer we...  positive\n","3  basically there family little boy jake think t...  negative\n","4  petter matteis love time money visually stunni...  positive\n","\n","Data has been split into 2509 training samples and 628 testing samples.\n","\n","Converting text data to numerical vectors with TF-IDF...\n","Vectorization complete.\n","The vocabulary size is 10000 features.\n","\n","--- Training the Logistic Regression Classifier ---\n","Logistic Regression Final Accuracy: 0.8790\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.88      0.88       321\n","           1       0.88      0.87      0.88       307\n","\n","    accuracy                           0.88       628\n","   macro avg       0.88      0.88      0.88       628\n","weighted avg       0.88      0.88      0.88       628\n","\n","\n","--- Training the Linear SVC Classifier ---\n","Linear SVC Final Accuracy: 0.8710\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.88      0.87       321\n","           1       0.87      0.86      0.87       307\n","\n","    accuracy                           0.87       628\n","   macro avg       0.87      0.87      0.87       628\n","weighted avg       0.87      0.87      0.87       628\n","\n","\n","Process finished!\n"]}]}]}